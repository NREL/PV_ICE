{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReEDS Scenarios on PV ICE Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore different scenarios for furture installation projections of PV (or any technology), ReEDS output data can be useful in providing standard scenarios. ReEDS installation projections from the Solar Futures DOE Report (2021) are used in this journal as input data to the PV ICE tool. \n",
    "\n",
    "Current sections include:\n",
    "\n",
    "<ol>\n",
    "    <li> ### Reading a standard ReEDS output file and saving it in a PV ICE input format </li>\n",
    "<li>### Reading scenarios of interest and running PV ICE tool </li>\n",
    "<li>###Plotting </li>\n",
    "<li>### GeoPlotting.</li>\n",
    "</ol>\n",
    "    Notes:\n",
    "   \n",
    "Scenarios of Interest:\n",
    "\tthe Ref.Mod, \n",
    "o\t95-by-35.Adv, and \n",
    "o\t95-by-35+Elec.Adv+DR ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PV_ICE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_ICE.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "testfolder = str(Path().resolve().parent.parent.parent / 'PV_ICE' / 'TEMP' / 'PCA')\n",
    "\n",
    "if not os.path.exists(testfolder):\n",
    "    os.makedirs(testfolder)\n",
    "\n",
    "print (\"Your simulation will be stored in %s\" % testfolder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportingMaterialFolder = str(Path().resolve().parent.parent / 'PV_ICE' / 'baselines' / 'SupportingMaterial')\n",
    "BaselinesFolder = str(Path().resolve().parent.parent / 'PV_ICE' / 'baselines')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading REEDS original file to get list of SCENARIOs, PCAs, and STATEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reedsFile = os.path.join(SupportingMaterialFolder, 'December Core Scenarios ReEDS Outputs Solar Futures v3a.xlsx')\n",
    "print (\"Input file is stored in %s\" % reedsFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = pd.read_excel(reedsFile,\n",
    "                        sheet_name=\"new installs PV\")\n",
    "                        #index_col=[0,2,3]) #this casts scenario, PCA and State as levels\n",
    "#now set year as an index in place\n",
    "#rawdf.drop(columns=['State'], inplace=True)\n",
    "rawdf.drop(columns=['Tech'], inplace=True)\n",
    "rawdf.set_index(['Scenario','Year','PCA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = list(rawdf.index.get_level_values('Scenario').unique())\n",
    "PCAs = list(rawdf.index.get_level_values('PCA').unique())\n",
    "STATEs = list(rawdf.index.get_level_values('State').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading GIS inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GISfile = os.path.join(SupportingMaterialFolder, 'gis_centroid_n.csv')\n",
    "GIS = pd.read_csv(GISfile)\n",
    "GIS = GIS.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS.loc['p1'].long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create ReEDS Scenarios BASELINE Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Module Baseline. Will be used later to populate all the columsn otehr than 'new_Installed_Capacity_[MW]' which will be supplied by the REEDS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PV_ICE\n",
    "r1 = PV_ICE.Simulation(name='Simulation1', path=testfolder)\n",
    "r1.createScenario(name='US', massmodulefile=r'..\\baselines\\baseline_modules_mass_US.csv')\n",
    "r1.scenMod_noCircularity() # Reeds Solar Future Study had circularity paths set to 0\n",
    "baseline = r1.scenario['US'].dataIn_m\n",
    "baseline = baseline.drop(columns=['new_Installed_Capacity_[MW]'])\n",
    "baseline.set_index('year', inplace=True)\n",
    "baseline.index = pd.PeriodIndex(baseline.index, freq='A')  # A -- Annual\n",
    "baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each Scenario and for each PCA, combine with baseline and save as input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set header dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportingMaterialFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "massmodulefile = os.path.join(BaselinesFolder, 'baseline_modules_mass_US.csv')\n",
    "\n",
    "with open(massmodulefile, newline='') as f:\n",
    "  reader = csv.reader(f)\n",
    "  row1 = next(reader)  # gets the first line\n",
    "  row2 = next(reader)  # gets the first line\n",
    "\n",
    "row11 = 'year'\n",
    "for x in row1[1:]:\n",
    "    row11 = row11 + ',' + x \n",
    "\n",
    "row22 = 'year'\n",
    "for x in row2[1:]:\n",
    "    row22 = row22 + ',' + x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range (len(rawdf.unstack(level=1))):\n",
    "    PCA = rawdf.unstack(level=1).iloc[ii].name[1]\n",
    "    SCEN = rawdf.unstack(level=1).iloc[ii].name[0]\n",
    "    SCEN=SCEN.replace('+', '_')\n",
    "    filetitle = SCEN+'_'+PCA +'.csv'\n",
    "    subtestfolder = os.path.join(testfolder, 'PCAs')\n",
    "    if not os.path.exists(subtestfolder):\n",
    "        os.makedirs(subtestfolder)\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "    A = rawdf.unstack(level=1).iloc[ii]\n",
    "    A = A.droplevel(level=0)\n",
    "    A.name = 'new_Installed_Capacity_[MW]'\n",
    "    A = pd.DataFrame(A)\n",
    "    A.index=pd.PeriodIndex(A.index, freq='A')\n",
    "    A = pd.DataFrame(A)\n",
    "    A['new_Installed_Capacity_[MW]'] = A['new_Installed_Capacity_[MW]'] * 0.85\n",
    "    A['new_Installed_Capacity_[MW]'] = A['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    # Add other columns\n",
    "    A = pd.concat([A, baseline.reindex(A.index)], axis=1)\n",
    "   \n",
    "    header = row11 + '\\n' + row22 + '\\n'\n",
    "    \n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        A.to_csv(ict, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scenarios in PV_ICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename difficult characters from Scenarios Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulationname = scenarios\n",
    "simulationname = [w.replace('+', '_') for w in simulationname]\n",
    "simulationname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downselect to Solar Future scenarios of interest\n",
    "\n",
    "Scenarios of Interest:\n",
    "<li> Ref.Mod\n",
    "<li> 95-by-35.Adv  \n",
    "<li> 95-by-35+Elec.Adv+DR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFscenarios = [simulationname[0], simulationname[4], simulationname[8]]\n",
    "SFscenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the 3 Scenarios and assign Baselines\n",
    "\n",
    "Keeping track of each scenario as its own PV ICE Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ii in range (0, 1): #len(scenarios):\n",
    "i = 0\n",
    "r1 = PV_ICE.Simulation(name=SFscenarios[i], path=testfolder)\n",
    "\n",
    "for jj in range (0, len(PCAs)): \n",
    "    filetitle = SFscenarios[i]+'_'+PCAs[jj]+'.csv'\n",
    "    filetitle = os.path.join(testfolder, 'PCAs', filetitle)    \n",
    "    r1.createScenario(name=PCAs[jj], massmodulefile=filetitle)\n",
    "    r1.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames']) \n",
    "    r1.trim_Years(startYear=2010, endYear=2050)\n",
    "    # All -- but these where not included in the Reeds initial study as we didnt have encapsulant or backsheet\n",
    "    # r1.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames', 'encapsulant', 'backsheet'], baselinefolder=r'..\\baselines')\n",
    "    r1.scenario[PCAs[jj]].latitude = GIS.loc[PCAs[jj]].lat\n",
    "    r1.scenario[PCAs[jj]].longitude = GIS.loc[PCAs[jj]].long\n",
    "\n",
    "i = 1\n",
    "r2 = PV_ICE.Simulation(name=SFscenarios[i], path=testfolder)\n",
    "\n",
    "for jj in range (0, len(PCAs)): \n",
    "    filetitle = SFscenarios[i]+'_'+PCAs[jj]+'.csv'\n",
    "    filetitle = os.path.join(testfolder, 'PCAs', filetitle)        \n",
    "    r2.createScenario(name=PCAs[jj], massmodulefile=filetitle)\n",
    "    r2.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames']) \n",
    "    r2.trim_Years(startYear=2010, endYear=2050)\n",
    "    # All -- but these where not included in the Reeds initial study as we didnt have encapsulant or backsheet\n",
    "    # r2.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames', 'encapsulant', 'backsheet'], baselinefolder=r'..\\baselines')\n",
    "    r2.scenario[PCAs[jj]].latitude = GIS.loc[PCAs[jj]].lat\n",
    "    r2.scenario[PCAs[jj]].longitude = GIS.loc[PCAs[jj]].long\n",
    "\n",
    "i = 2\n",
    "r3 = PV_ICE.Simulation(name=SFscenarios[i], path=testfolder)\n",
    "for jj in range (0, len(PCAs)): \n",
    "    filetitle = SFscenarios[i]+'_'+PCAs[jj]+'.csv'\n",
    "    filetitle = os.path.join(testfolder, 'PCAs', filetitle)        \n",
    "    r3.createScenario(name=PCAs[jj], massmodulefile=filetitle)\n",
    "    r3.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames']) #\n",
    "    r3.trim_Years(startYear=2010, endYear=2050)\n",
    "    # All -- but these where not included in the Reeds initial study as we didnt have encapsulant or backsheet\n",
    "    # r3.scenario[PCAs[jj]].addMaterials(['glass', 'silicon', 'silver', 'copper', 'aluminium_frames', 'encapsulant', 'backsheet'], baselinefolder=r'..\\baselines')\n",
    "    r3.scenario[PCAs[jj]].latitude = GIS.loc[PCAs[jj]].lat\n",
    "    r3.scenario[PCAs[jj]].longitude = GIS.loc[PCAs[jj]].long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Set characteristics of Recycling to SF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRENA= False\n",
    "PERFECTMFG = True\n",
    "\n",
    "mats = ['glass', 'silicon','silver','copper','aluminum']\n",
    "\n",
    "ELorRL = 'EL'\n",
    "if IRENA:\n",
    "    if ELorRL == 'RL':\n",
    "        r1.scenMod_IRENIFY(ELorRL='RL')\n",
    "        r2.scenMod_IRENIFY(ELorRL='RL')\n",
    "        r3.scenMod_IRENIFY(ELorRL='RL')\n",
    "\n",
    "    if ELorRL == 'EL':\n",
    "        r1.scenMod_IRENIFY(ELorRL='EL')\n",
    "        r2.scenMod_IRENIFY(ELorRL='EL')\n",
    "        r3.scenMod_IRENIFY(ELorRL='EL')\n",
    "    \n",
    "    \n",
    "    if PERFECTMFG:\n",
    "        r1.scenMod_PerfectManufacturing()\n",
    "        r2.scenMod_PerfectManufacturing()\n",
    "        r3.scenMod_PerfectManufacturing()\n",
    "\n",
    "    title_Method = 'Irena_'+ELorRL\n",
    "else:\n",
    "    title_Method = 'PVICE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mass Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.calculateMassFlow()\n",
    "r2.calculateMassFlow()\n",
    "r3.calculateMassFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCAs:\", r1.scenario.keys())\n",
    "print(\"Module Keys:\", r1.scenario[PCAs[jj]].dataIn_m.keys())\n",
    "print(\"Material Keys: \", r1.scenario[PCAs[jj]].material['glass'].matdataIn_m.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "r1.plotScenariosComparison(keyword='Cumulative_Area_disposedby_Failure')\n",
    "r1.plotMaterialComparisonAcrossScenarios(material='silicon', keyword='mat_Total_Landfilled')\n",
    "r1.scenario['p1'].dataIn_m.head(21)\n",
    "r2.scenario['p1'].dataIn_m.head(21)\n",
    "r3.scenario['p1'].dataIn_m.head(21)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USyearly1, UScum1 = r1.aggregateResults()\n",
    "USyearly2, UScum2 = r2.aggregateResults()\n",
    "USyearly3, UScum3 = r3.aggregateResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USyearly1.to_csv('USyearly_'+r1.name+'.csv')\n",
    "UScum1.to_csv('UScum_'+r1.name+'.csv')\n",
    "USyearly2.to_csv('USyearly_'+r2.name+'.csv')\n",
    "UScum2.to_csv('UScum_'+r2.name+'.csv')\n",
    "USyearly3.to_csv('USyearly_'+r3.name+'.csv')\n",
    "UScum3.to_csv('UScum_'+r3.name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Data Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA vs. Cumulative Waste by 2050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3 significant numbers rounding\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFScenarios[kk].scenario[PCAs[zz]].data.year\n",
    "\n",
    "Index 20 --> 2030\n",
    "\n",
    "Index 30 --> 2040\n",
    "\n",
    "Index 40 --> 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2030 = 20\n",
    "idx2040 = 30\n",
    "idx2050 = 40\n",
    "print(\"index \", idx2030, \" is year \", r1.scenario[PCAs[0]].dataIn_m['year'].iloc[idx2030])\n",
    "print(\"index \", idx2040, \" is year \", r1.scenario[PCAs[0]].dataIn_m['year'].iloc[idx2040])\n",
    "print(\"index \", idx2050, \" is year \", r1.scenario[PCAs[0]].dataIn_m['year'].iloc[idx2050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - PCA Cumulative Virgin Needs by 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = ['glass', 'silicon', 'silver', 'copper', 'aluminium_frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='mat_Virgin_Stock'\n",
    "\n",
    "SFScenarios = [r1, r2, r3]\n",
    "# Loop over SF Scenarios\n",
    "\n",
    "scenariolist = pd.DataFrame()\n",
    "for kk in range(0, 3):\n",
    "    # Loop over Materials\n",
    "    \n",
    "    materiallist = []\n",
    "    for ii in range (0, len(materials)):    \n",
    "        \n",
    "        keywordsum = []\n",
    "        for zz in range (0, len(PCAs)):\n",
    "            keywordsum.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword].sum())\n",
    "    \n",
    "        materiallist.append(keywordsum)\n",
    "    df = pd.DataFrame (materiallist,columns=PCAs, index = materials)\n",
    "    df = df.T\n",
    "    df = df.add_prefix(SFScenarios[kk].name+'_')\n",
    "    scenariolist = pd.concat([scenariolist , df], axis=1)\n",
    "\n",
    "scenariolist = scenariolist/1000000 # Converting to Metric Tons\n",
    "#scenariolist = scenariolist.applymap(lambda x: round(x, N - int(np.floor(np.log10(abs(x))))))\n",
    "#scenariolist = scenariolist.applymap(lambda x: int(x))\n",
    "scenariolist.to_csv(title_Method+' 1 - PCA Cumulative2050 VirginMaterialNeeds_tons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - PCA Cumulative EoL Only Waste by 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='mat_Total_EOL_Landfilled'\n",
    "\n",
    "SFScenarios = [r1, r2, r3]\n",
    "# Loop over SF Scenarios\n",
    "\n",
    "scenariolist = pd.DataFrame()\n",
    "for kk in range(0, 3):\n",
    "    # Loop over Materials\n",
    "    \n",
    "    materiallist = []\n",
    "    for ii in range (0, len(materials)):    \n",
    "        \n",
    "        keywordsum = []\n",
    "        for zz in range (0, len(PCAs)):\n",
    "            keywordsum.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword].sum())\n",
    "    \n",
    "        materiallist.append(keywordsum)\n",
    "    df = pd.DataFrame (materiallist,columns=PCAs, index = materials)\n",
    "    df = df.T\n",
    "    df = df.add_prefix(SFScenarios[kk].name+'_')\n",
    "    scenariolist = pd.concat([scenariolist , df], axis=1)\n",
    "\n",
    "scenariolist = scenariolist/1000000 # Converting to Metric Tons\n",
    "#scenariolist = scenariolist.applymap(lambda x: round(x, N - int(np.floor(np.log10(abs(x))))))\n",
    "#scenariolist = scenariolist.applymap(lambda x: int(x))\n",
    "scenariolist.to_csv(title_Method+' 2 - PCA Cumulative2050 Waste EOL_tons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - PCA Yearly Virgin Needs 2030 2040 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='mat_Virgin_Stock'\n",
    "\n",
    "SFScenarios = [r1, r2, r3]\n",
    "# Loop over SF Scenarios\n",
    "\n",
    "scenariolist = pd.DataFrame()\n",
    "for kk in range(0, 3):\n",
    "    # Loop over Materials\n",
    "    materiallist = pd.DataFrame()\n",
    "\n",
    "    for ii in range (0, len(materials)):    \n",
    "        \n",
    "        keywordsum2030 = []\n",
    "        keywordsum2040 = []\n",
    "        keywordsum2050 = []\n",
    "\n",
    "        for zz in range (0, len(PCAs)):\n",
    "            keywordsum2030.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2030])\n",
    "            keywordsum2040.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2040])\n",
    "            keywordsum2050.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2050])\n",
    "    \n",
    "        yearlylist = pd.DataFrame([keywordsum2030, keywordsum2040, keywordsum2050], columns=PCAs, index = [2030, 2040, 2050])\n",
    "        yearlylist = yearlylist.T\n",
    "        yearlylist = yearlylist.add_prefix(materials[ii]+'_')\n",
    "        materiallist = pd.concat([materiallist, yearlylist], axis=1)\n",
    "    materiallist = materiallist.add_prefix(SFScenarios[kk].name+'_')\n",
    "    scenariolist = pd.concat([scenariolist , materiallist], axis=1)\n",
    "\n",
    "scenariolist = scenariolist/1000000   # Converting to Metric Tons\n",
    "#scenariolist = scenariolist.applymap(lambda x: round(x, N - int(np.floor(np.log10(abs(x))))))\n",
    "#scenariolist = scenariolist.applymap(lambda x: int(x))\n",
    "scenariolist.to_csv(title_Method+' 3 - PCA Yearly 2030 2040 2050 VirginMaterialNeeds_tons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - PCA Yearly EoL Waste 2030 2040 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='mat_Total_Landfilled'\n",
    "\n",
    "SFScenarios = [r1, r2, r3]\n",
    "# Loop over SF Scenarios\n",
    "\n",
    "scenariolist = pd.DataFrame()\n",
    "for kk in range(0, 3):\n",
    "    # Loop over Materials\n",
    "    materiallist = pd.DataFrame()\n",
    "\n",
    "    for ii in range (0, len(materials)):    \n",
    "        \n",
    "        keywordsum2030 = []\n",
    "        keywordsum2040 = []\n",
    "        keywordsum2050 = []\n",
    "\n",
    "        for zz in range (0, len(PCAs)):\n",
    "            keywordsum2030.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2030])\n",
    "            keywordsum2040.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2040])\n",
    "            keywordsum2050.append(SFScenarios[kk].scenario[PCAs[zz]].material[materials[ii]].matdataOut_m[keyword][idx2050])\n",
    "    \n",
    "        yearlylist = pd.DataFrame([keywordsum2030, keywordsum2040, keywordsum2050], columns=PCAs, index = [2030, 2040, 2050])\n",
    "        yearlylist = yearlylist.T\n",
    "        yearlylist = yearlylist.add_prefix(materials[ii]+'_')\n",
    "        materiallist = pd.concat([materiallist, yearlylist], axis=1)\n",
    "    materiallist = materiallist.add_prefix(SFScenarios[kk].name+'_')\n",
    "    scenariolist = pd.concat([scenariolist , materiallist], axis=1)\n",
    "\n",
    "scenariolist = scenariolist/1000000   # Converting to Metric Tonnes\n",
    "#scenariolist = scenariolist.applymap(lambda x: round(x, N - int(np.floor(np.log10(abs(x))))))\n",
    "#scenariolist = scenariolist.applymap(lambda x: int(x))\n",
    "scenariolist.to_csv(title_Method+' 4 - PCA Yearly 2030 2040 2050 Waste_EOL_tons.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
